# 精度评测场景：评估指标解析

## 一、计算公式中 `n` 、`k` 与API配置文件中 `num_return_sequences` 的三者关系

### 1. `pass@k`的计算逻辑

> 此处仅简要描述pass@k一个指标作为参考，其它指标计算公式请参考[pass@k, cons@k, avg@n 的定义与关系](#二passk-consk-avgn-的定义与关系)

`pass@k`是代码生成任务的核心评估指标，用于衡量模型在生成`k`个候选解时，至少有一个解能通过所有测试用例的概率。其计算采用**无偏估计方法**，避免直接采样导致的方差问题。具体逻辑如下：

1. **生成样本与正确性统计**：

   - 对每个问题生成`n`个候选解（`n ≥ k`），其中`c`个解通过测试（即功能正确）。
   - 例如：生成`n=100`个样本，其中`c=20`个正确，则单样本通过率$P_{pass} = \frac{c}{n} = 0.2$。

2. **组合数学公式**：

   - 计算从`n`个样本中随机抽取`k`个样本时，**全部失败的概率**：

     $\frac{\binom{n-c}{k}}{\binom{n}{k}}$

   - `pass@k`为至少一个成功的概率：

     $pass@k = 1 - \frac{\binom{n-c}{k}}{\binom{n}{k}}$

   - **优化计算**：为避免阶乘溢出，代码实现使用数值优化：

    ```text
    pass@k = 1 - np.prod(1.0 - k / np.arange(n - c + 1, n + 1))
    ```

3. **无偏估计的意义**：
   > 在当前实现中，`k`和`n`暂时仅支持通过`num_return_sequences`配置为相同的值，故此处仅探讨无偏估计实现的优势
   - 直接采样`k`次会导致高方差（尤其当`k`较大时），而生成`n`（`n >> k`）个样本后通过组合公式估算，显著提升统计稳定性。

> **示例**：若`n=5`, `c=3`, `k=2`：
>
> - 全部失败概率 = `C(2,2)/C(5,2) = 1/10 = 0.1`
> - `pass@2 = 1 - 0.1 = 0.9`（即90%概率在2次尝试中至少成功一次）。

### 2. 参数中的`n`、`k`与`num_return_sequences`的关系

> **三者均需为正整数**

| **是否支持配置** | **参数**                   | **解释**                                               | **定义位置**                                     | **约束关系**                                          |
| --------------- | -------------------------- | ----------------------------------------------------- | ------------------------------------------------ | ----------------------------------------------------- |
| **否** | **`n`** | 副本数（即每个问题生成`n`个副本），也叫作总生成样本数 | 目前不支持单独配置，取值为`num_return_sequences` | 需满足：`n ≥ k`，但当前实现不支持单独配置，故无需关注 |
| **否** | **`k`** | 评估时随机抽取的样本数，决定`pass@k`的抽样规模      | 目前不支持单独配置，取值为`num_return_sequences` | 需满足：`n ≥ k`，但当前实现不支持单独配置，故无需关注 |
| **是** | **`num_return_sequences`** | **单条请求独立重复推理次数**    | API模型配置文件，默认为`1`                      | - |

### 3. 总结

- **pass@k逻辑**：基于组合数学的无偏估计，解决直接采样的高方差问题。
- 当前实现的计算逻辑中的**参数关系与约束**：
  - `n`和`k`目前不支持单独配置，仅`num_return_sequences`可在**API配置文件**中指定
  - `n` = `k` = **`num_return_sequences`**
  - `pass@k`、`cons@k`和`avg@n`名称中的`k`或`n`均为`num_return_sequences`

> **由于`n`和`k`虽然仅在评估阶段用于指标计算，而`num_return_sequences`用于推理过程，但取值来自于API配置文件中的`num_return_sequences`，所以在执行评估阶段（`--mode eval`）时，请确保reuse的推理结果中，配置的`num_return_sequences`与当前`num_return_sequences`值保持一致。**

---

## 二、pass@k, cons@k, avg@n 的定义与关系

### 1. 背景介绍

在大语言模型和多模态理解强化学习评估中，`pass@k`、`cons@k` 和 `avg@n` 是三个核心指标，用于从不同维度衡量模型在多次推理中的表现。这些指标适用于代码生成、数学推理、强化学习等需要**多次独立推理**的任务场景，提供对模型性能的统计学意义上的多维度评估。

### 2. 指标定义与计算

#### 2.1 指标定义表

| **指标**   | **数学定义**                               | **计算逻辑**                   | **评估目标**         | **值域** |
| ---------- | ------------------------------------------ | ------------------------------ | -------------------- | -------- |
| **pass@k** | $1−\prod_{j=n−c+1}^{n} (1−\frac{k}{j})$    | 至少一次正确的概率（无偏估计） | 模型解决能力的可靠性 | [0, 1]   |
| **cons@k** | $\frac{1}{N} \sum_{i=1}^{N} I(c_i > k/2)$  | 多数正确的概率估计             | 输出结果的稳定性     | [0, 1]   |
| **avg@n**  | $\frac{1}{N} \sum_{i=1}^{N} \frac{c_i}{n}$ | 平均样本正确率                 | 预测结果的整体准确性 | [0, 1]   |

> 其中：
>
> - N：问题总数（即数据集中问题的数量）。
> - n：每个问题的重复推理次数（总生成样本数），对应于代码中的 `n`参数。
> - k：评估抽样数，用于计算 pass@k 和 cons@k，对应于代码中的 `k`参数。
> - $c_i$：问题 i的正确次数（即该问题中通过测试的样本数量）。
> - $I(⋅)$：指示函数（条件满足为1，否则为0）
> - 公式中的乘积项索引 j从 n−c+1到 n，确保数值稳定性。

#### 2.2 计算逻辑详解

- **pass@k**：基于无偏估计方法，避免直接采样的方差问题。代码中使用 `compute_pass_at_k(n, c, k)`函数计算，其中 `n`是每个问题的总样本数，`c`是正确样本数，`k`是抽样数。公式等价于组合数学形式 $1 - \frac{\binom{n-c}{k}}{\binom{n}{k}}$，但采用乘积形式优化计算。
- **cons@k**：表示模型输出的“一致性”或“稳定性”，即多数样本正确的比例。代码中对于每个问题，如果正确样本数 $c$ 超过 $k/2$，则计为1，否则计为0，然后在所有问题上取平均。这直接反映了多数投票的准确率。
- **avg@n**：表示所有问题的平均样本级别准确率。代码中对于每个问题计算 `c / n`（正确率），然后在所有问题上取平均。这反映了模型预测的整体准确性。

#### 2.3 计算示例（`num_return_sequences=3`，即`n`、`k` = `3`）

```plaintext
问题1：预测 [A, A, X] → 正确次数=2
问题2：预测 [B, C, B] → 正确次数=2
问题3：预测 [X, X, C] → 正确次数=1
问题4：预测 [X, X, X] → 正确次数=0

pass@3 = (1.0 + 1.0 + 1.0 + 0.0)/4 = 0.75（问题1、2、3至少一次正确，问题4没有）
avg@3 = (2/3 + 2/3 + 1/3 + 0/3)/4 = (0.6667 + 0.6667 + 0.3333 + 0.0)/4 ≈ 0.4167
cons@3 = (1 + 1 + 0 + 0)/4 = 0.5（问题1和2多数票正确，问题3和4不正确）
```

### 3. `cons@k` vs  `avg@n`

#### 3.1 大小关系分析

> 由于统计学意义上的定义，**`pass@k`总是大于或等于 `avg@n`和 `cons@k`，不可能存在 `pass@k`小于其他两个指标的情况**，故此处**不比较`pass@k`与其它两个指标**

`cons@k`和`avg@n`的大小关系不确定，主要取决于模型预测的模式。以下是几种常见情况：

##### 情况一：`cons@k` > `avg@n`

- **场景**：模型预测倾向于高度一致但非完全正确（即多数问题有严格多数票正确，但正确率不是100%）。
- **示例**：设 `k=3`，有 2 个问题：
  - 问题1：预测 `[A, A, B]`，真实答案 `A`→ 正确次数 2，正确率 2/3 ≈ 0.667；多数票正确（`A`出现 2 次 > 1.5），所以 `cons`贡献 1。
  - 问题2：预测 `[B, B, C]`，真实答案 `B`→ 正确率 2/3 ≈ 0.667；多数票正确，`cons`贡献 1。
  - `avg@n`= (0.667 + 0.667) / 2 = 0.667
  - `cons@k`= (1 + 1) / 2 = 1.0
  - 因此 `cons@k`> `avg@n`。

##### 情况二：`cons@k` < `avg@n`

- **场景**：模型预测分散，没有多数票，但平均正确率较高（即正确预测均匀分布，但缺乏一致性）。
- **示例**：设 `k=3`，有 2 个问题：
  - 问题1：预测 `[A, B, C]`，真实答案 `A`→ 正确次数 1，正确率 1/3 ≈ 0.333；无严格多数票（所有出现次数 ≤ 1.5），所以 `cons`贡献 0。
  - 问题2：预测 `[A, B, C]`，真实答案 `B`→ 正确率 1/3 ≈ 0.333；无严格多数票，`cons`贡献 0。
  - `avg@n`= (0.333 + 0.333) / 2 = 0.333
  - `cons@k`= (0 + 0) / 2 = 0
  - 因此 `cons@k`< `avg@n`。

##### 情况三：`cons@k` ≈ `avg@n`

- **场景**：模型预测几乎完美或完全错误，或者预测分布使得多数票正确率与平均正确率相近。
- **示例**：设 `k=3`，有 2 个问题：
  - 问题1：预测 `[A, A, A]`，真实答案 `A`→ 正确率 1.0；多数票正确，`cons`贡献 1。
  - 问题2：预测 `[B, B, B]`，真实答案 `C`→ 正确率 0.0；多数票错误，`cons`贡献 0。
  - `avg@n`= (1.0 + 0.0) / 2 = 0.5
  - `cons@k`= (1 + 0) / 2 = 0.5
  - 因此 `cons@k` = `avg@n`。

#### 3.2 一般趋势

- 当模型预测高度一致（即多数问题有严格多数票正确）时，`cons@k`可能高于 `avg@n`，因为 `cons@k`只要求多数票正确，而 `avg@n`受错误预测拖累。
- 当模型预测分散（即多数问题无严格多数票）但正确率平均较高时，`avg@n`可能高于 `cons@k`，因为 `avg@n`奖励部分正确，而 `cons@k`要求多数票正确。
- 在理想情况下（所有预测正确或所有预测错误），两者相近。
- 在实际应用中（如强化学习场景下的多轮推理），`cons@k`通常用于评估稳定性，而 `avg@n`评估整体准确性。两者互补，没有固定大小关系。

### 4. 总结与建议

1. **指标选择原则**
   - 优先`pass@k`评估模型潜力
   - 用`cons@k`验证稳定性
   - 用`avg@n`衡量整体性能

2. **常见解读误区**
   - 仅关注`pass@1`：忽略模型多次尝试的潜力
   - 忽视`cons@k`：可能导致生产环境不稳定
   - 单独使用`avg@n`：无法区分一致性和容错性

3. **指标应用与决策指导**
   > **以下阈值均为假设定义**：高(>0.8), 中(0.5-0.8), 低(<0.5)
   > **以下决策相关内容仅作参考**

   - 应用场景推荐

     | **场景类型**                         | **核心指标** | **辅助指标**    | **目标值**                 |
     | ------------------------------------ | ------------ | --------------- | -------------------------- |
     | **可靠性优先**（医疗诊断、金融分析） | cons@k       | pass@k          | cons@k > 0.8, pass@k > 0.9 |
     | **容错性优先**（代码生成、探索任务） | pass@k       | avg@n           | pass@k > 0.8, avg@n > 0.7  |
     | **平衡评估**（通用AI助手）           | avg@n        | cons@k + pass@k | avg@n > 0.75               |

   - 决策指导矩阵

     | **指标组合**                    | **模型状态**     | **改进方向**                     |
     | ------------------------------- | ---------------- | -------------------------------- |
     | **高pass@k, 中avg@n, 低cons@k** | 潜力大但稳定性差 | 增强一致性（温度惩罚、投票机制） |
     | **中pass@k, 中avg@n, 中cons@k** | 均衡但需提升     | 全面优化（数据增强、提示工程）   |
     | **低pass@k, 低avg@n, 高cons@k** | 系统性偏差       | 检查数据/提示工程/模型偏差       |
     | **低pass@k, 低avg@n, 低cons@k** | 几乎失效         | 重新训练或更换模型架构           |

通过综合使用这三个指标，可以较为全面评估大语言模型的性能特征，为模型优化和应用部署提供具有统计学意义的科学依据。

### 5. 注意事项

> 当前**并非所有**数据集配置文件采用的评估器(`Evaluator`)支持这三种指标的计算，当数据集配置文件中`eval_cfg`指定的`Evaluator`未实现返回计算所需的指标时，则结果显示回退到仅计算原始用于精度表示的指标。

---

## 三、`accuracy (n runs average)` 与 `avg@n` 的差异分析

### 数据集示例：textvqa

> 以下关于计算部分的数学公式均为textvqa数据集评估类TEXTEvaluator中代码实现评估的数学逻辑

#### 1. 指标定义

- **`accuracy (n runs average)`**

  副本级软准确率（相似度）平均值

  **计算公式**:
  $\frac{1}{n} \sum_{j=1}^{n} \left( \frac{1}{D} \sum_{i=1}^{D} \text{avg_acc}_{ij} \right)$

  - n: 副本数量
  - D: 数据点数量
  - $\text{avg_acc}_{ij}$: 数据点 i在副本 j中的软正确性值（连续值 0-1）

- **`avg@n`**

  数据点级硬正确率（相似度是否过阈值`0.5`）平均值

  **计算公式**:

  $\frac{1}{D} \sum_{i=1}^{D} (\frac{1}{n} \sum_{j=1}^{n} H_{ij})$

  - $H_{ij}$: 硬正确性标记（二值：0 或 1）
  - $H_{ij} = \begin{cases} 1 & \text{if } \text{avg_acc}_{ij} > 0.5 \\ 0 & \text{otherwise} \end{cases}$

#### 2. 值不同的根本原因

两个指标使用不同的正确性度量：

- **软正确性**（`accuracy`）：

  连续值（0-1），反映预测与参考答案的部分匹配程度

  $\text{avg_acc}_{ij} = \frac{1}{K} \sum_{k=1}^{K} \text{match_score}$（K为参考答案数量）

- **硬正确性**（`avg@n`）：

  二值（0/1），基于阈值判断: $H_{ij} = \mathbb{I}(\text{avg_acc}_{ij} > 0.5)$

#### 3. 数学差异机制

设某数据点在 n个副本中的 $\text{avg_acc}$ 值：

$[a_1,a_2,...,a_n]$

则：

- $accuracy=\frac{1}{n} \sum_{j=1}^{n}a_j$
- $avg@n=\frac{1}{n}\sum_{j=1}^{n} \mathbb{I}(a_j > 0.5)$

##### 差异产生条件

当存在 $a_j∈(0,0.5)∪(0.5,1)$ 时（即非0/1的中间值），二者必然不等。

##### 示例计算证明

假设一个数据点在n=3个副本中的预测：

```text
- 副本1：avg_acc = 0.6→ correct = True
- 副本2：avg_acc = 0.4→ correct = False
- 副本3：avg_acc = 0.6→ correct = True
```

计算过程：

- accuracy (n runs average)：
  - 副本级accuracy = (0.6 + 0.4 + 0.6)/3 ≈ 0.533
  - 全局值 = 0.533（若多个数据点则再平均）

- avg@n：
  - 该数据点正确率 = 2/3 ≈ 0.666（因为2个correct=True）
  - 全局值 = 0.666（若多个数据点则再平均）

⇒ 两个指标值不同（0.533 vs 0.666）

#### 4. 差异的合理性

1. **评估目标不同**：
   - `accuracy`：衡量预测的平均匹配质量（精细评估）
   - `avg@n`：衡量预测超过阈值的比例（一致性评估）
2. **任务适配性**：
   - 如示例用于分析的textvqa数据集的Evaluator任务需要软正确性（其它数据集可能有多个合理变体）
   - 硬正确性用于模型鲁棒性分析
3. **数学正确性**：
   - 两个指标的计算公式在各自定义下均正确
   - 差异源于输入数据性质（软 vs 硬），非计算错误

#### 5. 值相同的特殊情况

当所有 $\text{avg_acc}_{ij} \in \{0, 1\}$时（即完全匹配或完全不匹配）：

accuracy=avg@n

#### 6. 示例总结

| 特征         | `accuracy (n runs average)`         | `avg@n`                             |
| ------------ | ----------------------------------- | ----------------------------------- |
| **度量类型** | 软正确性（连续值）                  | 硬正确性（二值）                    |
| **计算层级** | 先数据点平均 → 再副本平均           | 先副本平均 → 再数据点平均           |
| **核心公式** | $\frac{1}{nD} \sum \text{avg_acc}$ | $\frac{1}{D} \sum\frac{correct}{n}$ |
| **适用场景** | 精细质量评估                        | 一致性/鲁棒性评估                   |

### 差异归因

通过以上对`textvqa`数据集的指标分析，可以发现当在数据集配置文件中的评估方式（即`eval_cfg`中指定的`Evaluator`类下实现的`score`函数）中对`accuracy`或其它表示精确率指标(如`livecodebench`数据集的则为`pass@1`)的计算逻辑与`details`字段的判断逻辑不同时，则会出现` avg@n`和`accuracy (n runs average)`两个指标存在差异的现象，而**这种差异是合理的、符合统计学意义的，不是由代码错误导致的**。
