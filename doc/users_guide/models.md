# æ¨¡å‹é…ç½®è¯´æ˜
AISBench Benchmark æ”¯æŒä¸¤ç±»æ¨¡å‹åç«¯ï¼š
- [æœåŠ¡åŒ–æ¨ç†åç«¯](#æœåŠ¡åŒ–æ¨ç†åç«¯)
- [æœ¬åœ°æ¨¡å‹åç«¯](#æœ¬åœ°æ¨¡å‹åç«¯)

> âš ï¸ æ³¨æ„ï¼š ä¸èƒ½åŒæ—¶æŒ‡å®šä¸¤ç§åç«¯ã€‚
## æœåŠ¡åŒ–æ¨ç†åç«¯
AISBench Benchmark æ”¯æŒå¤šç§æœåŠ¡åŒ–æ¨ç†åç«¯ï¼ŒåŒ…æ‹¬ vLLMã€SGLangã€Tritonã€MindIEã€TGI ç­‰ã€‚è¿™äº›åç«¯é€šè¿‡æš´éœ²çš„ HTTP API æ¥å£æ¥æ”¶æ¨ç†è¯·æ±‚å¹¶è¿”å›ç»“æœã€‚ï¼ˆç›®å‰ä¸æ”¯æŒ HTTPS æ¥å£ï¼‰

ä»¥åœ¨ GPU ä¸Šéƒ¨ç½²çš„ vLLM æ¨ç†æœåŠ¡ä¸ºä¾‹ï¼Œæ‚¨å¯ä»¥å‚è€ƒ [vLLM å®˜æ–¹æ–‡æ¡£](https://docs.vllm.ai/en/stable/getting_started/quickstart.html) å¯åŠ¨æœåŠ¡ã€‚

ä¸åŒæœåŠ¡åŒ–åç«¯å¯¹åº”çš„æ¨¡å‹é…ç½®å¦‚ä¸‹ï¼š
| æ¨¡å‹é…ç½®åç§°| ç®€ä»‹| ä½¿ç”¨å‰æ| æ¥å£ç±»å‹ | æ”¯æŒçš„æ•°æ®é›† Prompt æ ¼å¼ | é…ç½®æ–‡ä»¶è·¯å¾„|
| ---------- | ---------- | ---------- | ---------- | ---------- | ---------- |
| `vllm_api_general` | é€šè¿‡ vLLM å…¼å®¹ OpenAI çš„ API è®¿é—®æ¨ç†æœåŠ¡ï¼Œæ¥å£ä¸º `v1/completions`| åŸºäº vLLM ç‰ˆæœ¬æ”¯æŒ `v1/completions` å­æœåŠ¡| æ–‡æœ¬æ¥å£ | å­—ç¬¦ä¸²æ ¼å¼| [vllm_api_general.py](../../ais_bench/benchmark/configs/models/vllm_api/vllm_api_general.py)|
| `vllm_api_general_stream`| æµå¼è®¿é—® vLLM æ¨ç†æœåŠ¡ï¼Œæ¥å£ä¸º `v1/completions`| åŸºäº vLLM ç‰ˆæœ¬æ”¯æŒ `v1/completions` å­æœåŠ¡| æµå¼æ¥å£ | å­—ç¬¦ä¸²æ ¼å¼| [vllm_api_general_stream.py](../../ais_bench/benchmark/configs/models/vllm_api/vllm_api_general_stream.py) |
| `vllm_api_general_chat`  | é€šè¿‡ vLLM å…¼å®¹ OpenAI çš„ API è®¿é—®æ¨ç†æœåŠ¡ï¼Œæ¥å£ä¸º `v1/chat/completions` | åŸºäº vLLM ç‰ˆæœ¬æ”¯æŒ `v1/chat/completions` å­æœåŠ¡ | æ–‡æœ¬æ¥å£ | å­—ç¬¦ä¸²æ ¼å¼ã€å¯¹è¯æ ¼å¼ã€å¤šæ¨¡æ€æ ¼å¼ | [vllm_api_general_chat.py](../../ais_bench/benchmark/configs/models/vllm_api/vllm_api_general_chat.py)  |
| `vllm_api_stream_chat`| æµå¼è®¿é—® vLLM æ¨ç†æœåŠ¡ï¼Œæ¥å£ä¸º `v1/chat/completions`| åŸºäº vLLM ç‰ˆæœ¬æ”¯æŒ `v1/chat/completions` å­æœåŠ¡ | æµå¼æ¥å£ | å­—ç¬¦ä¸²æ ¼å¼ã€å¯¹è¯æ ¼å¼ã€å¤šæ¨¡æ€æ ¼å¼ | [vllm_api_stream_chat.py](../../ais_bench/benchmark/configs/models/vllm_api/vllm_api_stream_chat.py) |
| `vllm_api_stream_chat_multiturn`| å¤šè½®å¯¹è¯åœºæ™¯çš„æµå¼è®¿é—® vLLM æ¨ç†æœåŠ¡ï¼Œæ¥å£ä¸º `v1/chat/completions`| åŸºäº vLLM ç‰ˆæœ¬æ”¯æŒ `v1/chat/completions` å­æœåŠ¡ | æµå¼æ¥å£ | å¯¹è¯æ ¼å¼ | [vllm_api_stream_chat_multiturn.py](../../ais_bench/benchmark/configs/models/vllm_api/vllm_api_stream_chat_multiturn.py) |
| `vllm_api_function_call_chat`| function callç²¾åº¦æµ‹è¯„åœºæ™¯è®¿é—® vLLM æ¨ç†æœåŠ¡çš„API ï¼Œæ¥å£ä¸º `v1/chat/completions`ï¼ˆåªé€‚ç”¨äº[BFCL](../../ais_bench/benchmark/configs/datasets/BFCL/README.md)æµ‹è¯„åœºæ™¯)| åŸºäº vLLM ç‰ˆæœ¬æ”¯æŒ `v1/chat/completions` å­æœåŠ¡ | æ–‡æœ¬æ¥å£ | å¯¹è¯æ ¼å¼ | [vllm_api_function_call_chat.py](../../ais_bench/benchmark/configs/models/vllm_api/vllm_api_function_call_chat.py) |
| `vllm_api_old`  | é€šè¿‡ vLLM å…¼å®¹ API è®¿é—®æ¨ç†æœåŠ¡ï¼Œæ¥å£ä¸º `generate`| åŸºäº vLLM ç‰ˆæœ¬æ”¯æŒ `generate` å­æœåŠ¡| æ–‡æœ¬æ¥å£ | å­—ç¬¦ä¸²æ ¼å¼ã€å¤šæ¨¡æ€æ ¼å¼| [vllm_api_old.py](../../ais_bench/benchmark/configs/models/vllm_api/vllm_api_old.py)|
| `mindie_stream_api_general` | é€šè¿‡ MindIE æµå¼ API è®¿é—®æ¨ç†æœåŠ¡ï¼Œæ¥å£ä¸º `infer`| åŸºäº MindIE ç‰ˆæœ¬æ”¯æŒ `infer` å­æœåŠ¡ | æµå¼æ¥å£ | å­—ç¬¦ä¸²æ ¼å¼ã€å¤šæ¨¡æ€æ ¼å¼| [mindie_stream_api_general.py](../../ais_bench/benchmark/configs/models/mindie_api/mindie_stream_api_general.py) |
| `triton_api_general`  | é€šè¿‡ Triton API è®¿é—®æ¨ç†æœåŠ¡ï¼Œæ¥å£ä¸º `v2/models/{model name}/generate`  | å¯åŠ¨æ”¯æŒ Triton API çš„æ¨ç†æœåŠ¡| æ–‡æœ¬æ¥å£ | å­—ç¬¦ä¸²æ ¼å¼ã€å¤šæ¨¡æ€æ ¼å¼| [triton_api_general.py](../../ais_bench/benchmark/configs/models/triton_api/triton_api_general.py) |
| `triton_stream_api_general` | é€šè¿‡ Triton æµå¼ API è®¿é—®æ¨ç†æœåŠ¡ï¼Œæ¥å£ä¸º `v2/models/{model name}/generate_stream` | å¯åŠ¨æ”¯æŒ Triton API çš„æ¨ç†æœåŠ¡| æµå¼æ¥å£ | å­—ç¬¦ä¸²æ ¼å¼ã€å¤šæ¨¡æ€æ ¼å¼ | [triton_stream_api_general.py](../../ais_bench/benchmark/configs/models/triton_api/triton_stream_api_general.py) |
| `tgi_api_general`  | é€šè¿‡ TGI API è®¿é—®æ¨ç†æœåŠ¡ï¼Œæ¥å£ä¸º `generate`| å¯åŠ¨æ”¯æŒ TGI API çš„æ¨ç†æœåŠ¡| æ–‡æœ¬æ¥å£ | å­—ç¬¦ä¸²æ ¼å¼ã€å¤šæ¨¡æ€æ ¼å¼| [tgi_api_general](../../ais_bench/benchmark/configs/models/tgi_api/tgi_api_general.py)|
| `tgi_stream_api_general` | é€šè¿‡ TGI æµå¼ API è®¿é—®æ¨ç†æœåŠ¡ï¼Œæ¥å£ä¸º `generate_stream`| å¯åŠ¨æ”¯æŒ TGI API çš„æ¨ç†æœåŠ¡| æµå¼æ¥å£ | å­—ç¬¦ä¸²æ ¼å¼ã€å¤šæ¨¡æ€æ ¼å¼| [tgi_stream_api_general](../../ais_bench/benchmark/configs/models/tgi_api/tgi_stream_api_general.py) |

### æœåŠ¡åŒ–æ¨ç†åç«¯é…ç½®å‚æ•°è¯´æ˜
æœåŠ¡åŒ–æ¨ç†åç«¯é…ç½®æ–‡ä»¶é‡‡ç”¨Pythonè¯­æ³•æ ¼å¼é…ç½®ï¼Œç¤ºä¾‹å¦‚ä¸‹ï¼š
```python
from ais_bench.benchmark.models import VLLMCustomAPI

models = [
    dict(
        attr="service",             # åç«¯ç±»å‹æ ‡è¯†
        type=VLLMCustomAPI,         # API ç±»å‹
        abbr='vllm-api-general',    # å”¯ä¸€æ ‡è¯†
        path="/weight/DeepSeek-R1", # æ¨¡å‹è·¯å¾„
        model="DeepSeek-R1",        # æ¨¡å‹åç§°
        request_rate=0,             # è¯·æ±‚é€Ÿç‡
        retry=2,                    # æœ€å¤§é‡è¯•æ¬¡æ•°
        host_ip="localhost",        # æ¨ç†æœåŠ¡ IP
        host_port=8080,             # æ¨ç†æœåŠ¡ç«¯å£
        max_out_len=512,            # æœ€å¤§è¾“å‡ºé•¿åº¦
        batch_size=1,               # è¯·æ±‚å¹¶å‘æ•°
        generation_kwargs=dict(     # åå¤„ç†å‚æ•°
            temperature=0.5,
            top_k=10,
            top_p=0.95,
            seed=None,
            repetition_penalty=1.03,
        )
    )
]

```

æœåŠ¡åŒ–æ¨ç†åç«¯å¯é…ç½®å‚æ•°è¯´æ˜å¦‚ä¸‹ï¼š
| å‚æ•°åç§° | å‚æ•°ç±»å‹ | é…ç½®è¯´æ˜ |
|----------|-----------|-------------|
| `attr` | String | æ¨ç†åç«¯ç±»å‹æ ‡è¯†ï¼Œå›ºå®šä¸º `service`ï¼ˆæœåŠ¡åŒ–æ¨ç†ï¼‰æˆ– `local`ï¼ˆæœ¬åœ°æ¨¡å‹ï¼‰ï¼Œä¸å¯é…ç½® |
| `type` | Python Class | API ç±»å‹ç±»åï¼Œç”±ç³»ç»Ÿè‡ªåŠ¨å…³è”ï¼Œç”¨æˆ·æ— éœ€æ‰‹åŠ¨é…ç½®ï¼Œå‚è€ƒ [æœåŠ¡åŒ–æ¨ç†åç«¯](#æœåŠ¡åŒ–æ¨ç†åç«¯) |
| `abbr` | String | æœåŠ¡åŒ–ä»»åŠ¡çš„å”¯ä¸€æ ‡è¯†ï¼Œç”¨äºåŒºåˆ†ä¸åŒä»»åŠ¡ï¼Œè‹±æ–‡å­—ç¬¦ä¸çŸ­æ¨ªçº¿ç»„åˆï¼Œä¾‹å¦‚ï¼š`vllm-api-general-chat` |
| `path` | String | Tokenizer è·¯å¾„ï¼Œé€šå¸¸ä¸æ¨¡å‹è·¯å¾„ç›¸åŒï¼Œä½¿ç”¨ `AutoTokenizer.from_pretrained(path)` åŠ è½½ã€‚æŒ‡å®šå¯è®¿é—®çš„æœ¬åœ°è·¯å¾„ï¼Œä¾‹å¦‚ï¼š`/weight/DeepSeek-R1` |
| `model` | String | æœåŠ¡ç«¯å¯è®¿é—®çš„æ¨¡å‹åç§°ï¼Œå¿…é¡»ä¸æœåŠ¡åŒ–éƒ¨ç½²æ—¶æŒ‡å®šçš„åç§°ä¸€è‡´ |
| `model_name` | String | ä»…é€‚ç”¨äº Triton æœåŠ¡ï¼Œæ‹¼æ¥ä¸º endpoint çš„ URI `/v2/models/{modelname}/{inferã€generateã€generate_stream}`ï¼Œåº”ä¸éƒ¨ç½²æ—¶åç§°ä¸€è‡´ |
| `request_rate` | Float | è¯·æ±‚å‘é€é€Ÿç‡ï¼ˆå•ä½ï¼šç§’ï¼‰ï¼Œæ¯éš” `1/request_rate` ç§’å‘é€ä¸€ä¸ªè¯·æ±‚ï¼›è‹¥å°äº 0.1 åˆ™è‡ªåŠ¨åˆå¹¶ä¸ºæ‰¹é‡å‘é€ã€‚åˆæ³•èŒƒå›´ï¼š[0, 64000] |
| `retry` | Int | è¿æ¥æœåŠ¡ç«¯å¤±è´¥åçš„æœ€å¤§é‡è¯•æ¬¡æ•°ã€‚åˆæ³•èŒƒå›´ï¼š[0, 1000] |
| `host_ip` | String | æœåŠ¡ç«¯ IP åœ°å€ï¼Œæ”¯æŒåˆæ³• IPv4 æˆ– IPv6ï¼Œä¾‹å¦‚ï¼š`127.0.0.1` |
| `host_port` | Int | æœåŠ¡ç«¯ç«¯å£å·ï¼Œåº”ä¸æœåŠ¡åŒ–éƒ¨ç½²æŒ‡å®šçš„ç«¯å£ä¸€è‡´ |
| `max_out_len` | Int | æ¨ç†å“åº”çš„æœ€å¤§è¾“å‡ºé•¿åº¦ï¼Œå®é™…é•¿åº¦å¯èƒ½å—æœåŠ¡ç«¯é™åˆ¶ã€‚åˆæ³•èŒƒå›´ï¼š(0, 131072] |
| `batch_size` | Int | è¯·æ±‚çš„å¹¶å‘æ‰¹å¤„ç†å¤§å°ã€‚åˆæ³•èŒƒå›´ï¼š(0, 64000] |
| `generation_kwargs` | Dict | æ¨ç†ç”Ÿæˆå‚æ•°é…ç½®ï¼Œä¾èµ–å…·ä½“çš„æœåŠ¡åŒ–åç«¯å’Œæ¥å£ç±»å‹ã€‚æ³¨æ„ï¼šå½“å‰ä¸æ”¯æŒ `best_of` å’Œ `n` ç­‰å¤šæ¬¡é‡‡æ ·å‚æ•°ï¼Œä½†æ”¯æŒé€šè¿‡`num_return_sequences`å‚æ•°è¿›è¡Œå¤šæ¬¡ç‹¬ç«‹æ¨ç†(å…·ä½“è¯·å‚è€ƒğŸ”—[Text Generation æ–‡æ¡£](https://huggingface.co/docs/transformers/v4.18.0/en/main_classes/text_generation#transformers.generation_utils.GenerationMixin.generate.num_return_sequences\(int,)ä¸­`num_return_sequences`çš„ä½œç”¨) |
| `returns_tool_calls` | Bool | æ§åˆ¶å‡½æ•°è°ƒç”¨ä¿¡æ¯çš„æå–æ–¹å¼ã€‚å½“è®¾ç½®ä¸ºTrueæ—¶ï¼Œç³»ç»Ÿä»APIå“åº”çš„`tool_calls`å­—æ®µä¸­æå–å‡½æ•°è°ƒç”¨ä¿¡æ¯ï¼›å½“è®¾ç½®ä¸ºFalseæ—¶ï¼Œç³»ç»Ÿä»`content`å­—æ®µä¸­è§£æå‡½æ•°è°ƒç”¨ä¿¡æ¯ |
| `pred_postprocessor` | Dict | æ¨¡å‹è¾“å‡ºç»“æœçš„åå¤„ç†é…ç½®ã€‚ç”¨äºå¯¹åŸå§‹æ¨¡å‹è¾“å‡ºè¿›è¡Œæ ¼å¼åŒ–ã€æ¸…ç†æˆ–è½¬æ¢ï¼Œä»¥æ»¡è¶³ç‰¹å®šè¯„ä¼°ä»»åŠ¡çš„è¦æ±‚ |

**æ³¨æ„äº‹é¡¹ï¼š**
- `request_rate` å—ç¡¬ä»¶æ€§èƒ½å½±å“ï¼Œå¯é€šè¿‡å¢åŠ   ğŸ“š [WORKERS_NUM](./cli_args.md#é…ç½®å¸¸é‡æ–‡ä»¶å‚æ•°) æé«˜å¹¶å‘èƒ½åŠ›ã€‚
- `batch_size` è®¾ç½®è¿‡å¤§å¯èƒ½å¯¼è‡´ CPU å ç”¨è¿‡é«˜ï¼Œè¯·æ ¹æ®ç¡¬ä»¶æ¡ä»¶åˆç†é…ç½®ã€‚
- æœåŠ¡åŒ–æ¨ç†è¯„æµ‹ API é»˜è®¤ä½¿ç”¨çš„æœåŠ¡åœ°å€ä¸º `localhost:8080`ã€‚å®é™…ä½¿ç”¨æ—¶éœ€æ ¹æ®å®é™…éƒ¨ç½²ä¿®æ”¹ä¸ºæœåŠ¡åŒ–åç«¯çš„ IP å’Œç«¯å£ã€‚

## æœ¬åœ°æ¨¡å‹åç«¯
|æ¨¡å‹é…ç½®åç§°|ç®€ä»‹|ä½¿ç”¨å‰æ|æ”¯æŒçš„promptæ ¼å¼(å­—ç¬¦ä¸²æ ¼å¼æˆ–å¯¹è¯æ ¼å¼)|å¯¹åº”æºç é…ç½®æ–‡ä»¶è·¯å¾„|
| --- | --- | --- | --- | --- |
|`hf_base_model`|HuggingFace Base æ¨¡å‹åç«¯|å·²å®‰è£…è¯„æµ‹å·¥å…·åŸºç¡€ä¾èµ–ï¼Œéœ€åœ¨é…ç½®æ–‡ä»¶ä¸­æŒ‡å®š HuggingFace æ¨¡å‹æƒé‡è·¯å¾„ï¼ˆå½“å‰ä¸æ”¯æŒè‡ªåŠ¨ä¸‹è½½ï¼‰|å­—ç¬¦ä¸²æ ¼å¼|[hf_base_model](../../ais_bench/benchmark/configs/models/hf_models/hf_base_model.py)|
|`hf_chat_model`|	HuggingFace Chat æ¨¡å‹åç«¯|å·²å®‰è£…è¯„æµ‹å·¥å…·åŸºç¡€ä¾èµ–ï¼Œéœ€åœ¨é…ç½®æ–‡ä»¶ä¸­æŒ‡å®š HuggingFace æ¨¡å‹æƒé‡è·¯å¾„ï¼ˆå½“å‰ä¸æ”¯æŒè‡ªåŠ¨ä¸‹è½½ï¼‰|å¯¹è¯æ ¼å¼|[hf_chat_model](../../ais_bench/benchmark/configs/models/hf_models/hf_chat_model.py)|

### æœ¬åœ°æ¨¡å‹åç«¯é…ç½®å‚æ•°è¯´æ˜
æœ¬åœ°æ¨¡å‹åç«¯é…ç½®æ–‡ä»¶é‡‡ç”¨Pythonè¯­æ³•æ ¼å¼é…ç½®ï¼Œç¤ºä¾‹å¦‚ä¸‹ï¼š
```python
from ais_bench.benchmark.models import HuggingFacewithChatTemplate

models = [
    dict(
        attr="local",                       # åç«¯ç±»å‹æ ‡è¯†
        type=HuggingFacewithChatTemplate,   # æ¨¡å‹ç±»å‹
        abbr='hf-chat-model',               # å”¯ä¸€æ ‡è¯†
        path='THUDM/chatglm-6b',            # æ¨¡å‹æƒé‡è·¯å¾„
        tokenizer_path='THUDM/chatglm-6b',  # Tokenizer è·¯å¾„
        model_kwargs=dict(                  # æ¨¡å‹åŠ è½½å‚æ•°
            device_map="auto",
            trust_remote_code=True
        ),
        max_out_len=512,                    # æœ€å¤§è¾“å‡ºé•¿åº¦
        batch_size=1,                       # è¯·æ±‚å¹¶å‘æ•°
        generation_kwargs=dict(             # ç”Ÿæˆå‚æ•°
            temperature=0.5,
            top_k=10,
            top_p=0.95,
            seed=None,
            repetition_penalty=1.03,
        )
    )
]
```

æœ¬åœ°æ¨¡å‹æ¨ç†åç«¯å¯é…ç½®å‚æ•°è¯´æ˜å¦‚ä¸‹ï¼š
| å‚æ•°åç§° | å‚æ•°ç±»å‹ | è¯´æ˜ä¸é…ç½® |
|----------|-----------|-------------|
| `attr` | String | åç«¯ç±»å‹æ ‡è¯†ï¼Œå›ºå®šä¸º `local`ï¼ˆæœ¬åœ°æ¨¡å‹ï¼‰æˆ– `service`ï¼ˆæœåŠ¡åŒ–æ¨ç†ï¼‰ |
| `type` | Python Class | æ¨¡å‹ç±»åç§°ï¼Œç”±ç³»ç»Ÿè‡ªåŠ¨å…³è”ï¼Œç”¨æˆ·æ— éœ€æ‰‹åŠ¨é…ç½® |
| `abbr` | String | æœ¬åœ°ä»»åŠ¡çš„å”¯ä¸€æ ‡è¯†ï¼Œç”¨äºåŒºåˆ†å¤šä»»åŠ¡ã€‚å»ºè®®ä½¿ç”¨è‹±æ–‡ä¸çŸ­æ¨ªçº¿ç»„åˆï¼Œå¦‚ï¼š`hf-chat-model` |
| `path` | String | æ¨¡å‹æƒé‡è·¯å¾„ï¼Œéœ€ä¸ºæœ¬åœ°å¯è®¿é—®è·¯å¾„ã€‚ä½¿ç”¨ `AutoModel.from_pretrained(path)` åŠ è½½ |
| `tokenizer_path` | String | Tokenizer è·¯å¾„ï¼Œé€šå¸¸ä¸æ¨¡å‹è·¯å¾„ä¸€è‡´ã€‚ä½¿ç”¨ `AutoTokenizer.from_pretrained(tokenizer_path)` åŠ è½½ |
| `tokenizer_kwargs` | Dict | Tokenizer åŠ è½½å‚æ•°ï¼Œå‚è€ƒ ğŸ”— [PreTrainedTokenizerBase æ–‡æ¡£](https://huggingface.co/docs/transformers/v4.50.0/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase) |
| `model_kwargs` | Dict | æ¨¡å‹åŠ è½½å‚æ•°ï¼Œå‚è€ƒ ğŸ”— [AutoModel é…ç½®](https://huggingface.co/docs/transformers/v4.50.0/en/model_doc/auto#transformers.AutoConfig.from_pretrained) |
| `generation_kwargs` | Dict | æ¨ç†ç”Ÿæˆå‚æ•°ï¼Œå‚è€ƒ ğŸ”— [Text Generation æ–‡æ¡£](https://huggingface.co/docs/transformers/v4.18.0/en/main_classes/text_generation) |
| `run_cfg` | Dict | è¿è¡Œé…ç½®ï¼ŒåŒ…å« `num_gpus`ï¼ˆä½¿ç”¨çš„ GPU æ•°é‡ï¼‰ä¸ `num_procs`ï¼ˆä½¿ç”¨çš„æœºå™¨è¿›ç¨‹æ•°ï¼‰ |
| `max_out_len` | Int | æ¨ç†ç”Ÿæˆçš„æœ€å¤§è¾“å‡º Token æ•°é‡ï¼Œåˆæ³•èŒƒå›´ï¼š(0, 131072] |
| `batch_size` | Int | æ¨ç†è¯·æ±‚çš„æ‰¹å¤„ç†å¤§å°ï¼Œåˆæ³•èŒƒå›´ï¼š(0, 64000] |
| `max_seq_len` | Int | æœ€å¤§è¾“å…¥åºåˆ—é•¿åº¦ï¼Œåˆæ³•èŒƒå›´ï¼š(0, 131072] |
| `batch_padding` | Bool | æ˜¯å¦å¯ç”¨æ‰¹é‡ paddingã€‚è®¾ç½®ä¸º `True` æˆ– `False` |